"""Chat parsing and preprocessing service."""
import logging
import re
from collections import defaultdict
from datetime import date, datetime
from typing import Dict, List, Optional

from .telegram_parser import TelegramMessage, parse_telegram_html
from .whatsapp_parser import parse_whatsapp_txt
from ..models.schemas import ChatStats, ParticipantStats

logger = logging.getLogger(__name__)

# ---- –®—É–º / —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è ----

MEDIA_PLACEHOLDERS = {
    "not included, change data exporting settings to download.",
    "[media omitted]",
    "<media omitted>",
    "‚Äéimage omitted",
    "‚Äéimage omitted.",
    "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ",
    "–º–µ–¥–∏–∞—Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç",
    "–ë–µ–∑ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤",
    "–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ–∑–≤–æ–Ω–æ–∫",
}

SYSTEM_PATTERNS = [
    r"—Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∑–≤–æ–Ω–∫–∏ .* –∑–∞—â–∏—â–µ–Ω—ã —Å–∫–≤–æ–∑–Ω—ã–º —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ–º",
    r"–≤—ã —Å–æ–∑–¥–∞–ª–∏ –≥—Ä—É–ø–ø—É",
    r"–≤—ã –∏–∑–º–µ–Ω–∏–ª–∏ —Ñ–æ—Ç–æ –≥—Ä—É–ø–ø—ã",
    r"–≤—ã –∏–∑–º–µ–Ω–∏–ª–∏ —Ç–µ–º—É –±–µ—Å–µ–¥—ã",
    r"–≤—ã –∑–∞–∫—Ä–µ–ø–∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ",
    r"–≤—ã —É–¥–∞–ª–∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ",
    r"–ë–µ–∑ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤",
    r"–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ–∑–≤–æ–Ω–æ–∫",
]

_system_regexes = [re.compile(pat, re.IGNORECASE) for pat in SYSTEM_PATTERNS]


def _is_noise_text(text: str) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç "—à—É–º–æ–º":
    - –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∑–∞–≥–ª—É—à–∫–∏ –º–µ–¥–∏–∞
    - —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (—Å–æ–∑–¥–∞–Ω–∏–µ/–∏–∑–º–µ–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã –∏ —Ç.–ø.)

    –í–ê–ñ–ù–û: emoji, –∫–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–ø–ª–∏–∫–∏, ¬´üëç¬ª, ¬´–æ–∫¬ª –∏ —Ç.–ø. ‚Äî –ù–ï —Å—á–∏—Ç–∞–µ–º —à—É–º–æ–º.
    """
    if not text:
        return True

    stripped = text.strip()
    if not stripped:
        return True

    low = stripped.lower()

    # –∑–∞–≥–ª—É—à–∫–∏ –º–µ–¥–∏–∞
    if low in MEDIA_PLACEHOLDERS:
        return True

    # —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–ø–æ —Ä–µ–≥—É–ª—è—Ä–∫–∞–º)
    for rx in _system_regexes:
        if rx.search(low):
            return True

    return False


def filter_noise_messages(messages: List[TelegramMessage]) -> List[TelegramMessage]:
    """
    –£–±–∏—Ä–∞–µ–º –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –º—É—Å–æ—Ä:
    - —á–∏—Å—Ç—ã–µ media-–∑–∞–≥–ª—É—à–∫–∏
    - —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    –≠–º–æ–¥–∑–∏ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –ù–ï —Ç—Ä–æ–≥–∞–µ–º.
    """
    before = len(messages)
    cleaned: List[TelegramMessage] = []

    for msg in messages:
        txt = msg.text or ""
        if _is_noise_text(txt):
            continue
        cleaned.append(msg)

    removed = before - len(cleaned)
    logger.info(
        "[noise_filter] before=%d, after=%d, removed=%d",
        before,
        len(cleaned),
        removed,
    )
    return cleaned


def filter_messages_by_date(
    messages: List[TelegramMessage],
    from_date: Optional[date],
    to_date: Optional[date],
) -> List[TelegramMessage]:
    """
    –§–∏–ª—å—Ç—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É –¥–∞—Ç (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ).
    –ï—Å–ª–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–ª–∞ –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Å–ø–∏—Å–æ–∫.
    """
    if not from_date and not to_date:
        return messages

    filtered: List[TelegramMessage] = []
    for msg in messages:
        if not msg.date:
            continue
        d = msg.date.date()
        if from_date and d < from_date:
            continue
        if to_date and d > to_date:
            continue
        filtered.append(msg)

    if not filtered:
        logger.warning(
            "–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–∞—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å, "
            "–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π.",
        )
        return messages

    return filtered


def compute_stats_from_messages(messages: List[TelegramMessage]) -> ChatStats:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π."""
    total = len(messages)

    per_user_length: Dict[str, List[int]] = defaultdict(list)
    dates: List[datetime] = []

    for msg in messages:
        per_user_length[msg.from_name].append(len(msg.text))
        if msg.date:
            dates.append(msg.date)

    participants_stats: List[ParticipantStats] = []
    for user, lengths in per_user_length.items():
        # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –Ω–∞—Å—Ç–æ—è—â–∏—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –≤–∏–¥–∞ USER_1, USER_2, ...
        if not user.startswith("USER_"):
            continue

        count = len(lengths)
        avg_len = sum(lengths) / count if count else 0
        participants_stats.append(
            ParticipantStats(
                id=user,
                messages_count=count,
                avg_message_length=round(avg_len, 1),
            )
        )

    participants_stats.sort(key=lambda p: p.messages_count, reverse=True)

    first_dt = min(dates) if dates else None
    last_dt = max(dates) if dates else None

    return ChatStats(
        total_messages=total,
        participants=participants_stats,
        first_message_at=first_dt,
        last_message_at=last_dt,
    )


def compute_stats_from_plain_text(text: str) -> ChatStats:
    """–ü—Ä–æ—Å—Ç–µ–π—à–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞."""
    lines = [ln for ln in text.splitlines() if ln.strip()]
    return ChatStats(
        total_messages=len(lines),
        participants=[],
        first_message_at=None,
        last_message_at=None,
    )


def parse_chat_text(
    chat_text: str,
    from_date: Optional[date] = None,
    to_date: Optional[date] = None,
) -> tuple[List[TelegramMessage], ChatStats]:
    """
    –ü–∞—Ä—Å–∏—Ç —Ç–µ–∫—Å—Ç —á–∞—Ç–∞, —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –¥–∞—Ç–µ –∏ —à—É–º—É, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.
    """
    is_html = "<html" in chat_text[:500].lower()

    if is_html:
        messages = parse_telegram_html(chat_text)
        if messages:
            by_date = filter_messages_by_date(messages, from_date, to_date)
            filtered = filter_noise_messages(by_date)
            stats = compute_stats_from_messages(filtered)
            return filtered, stats
        else:
            stats = compute_stats_from_plain_text(chat_text)
            return [], stats
    else:
        wa_messages = parse_whatsapp_txt(chat_text)
        if wa_messages:
            by_date = filter_messages_by_date(wa_messages, from_date, to_date)
            filtered = filter_noise_messages(by_date)
            stats = compute_stats_from_messages(filtered)
            return filtered, stats
        else:
            stats = compute_stats_from_plain_text(chat_text)
            return [], stats
